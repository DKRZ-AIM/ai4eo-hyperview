"""
This code is generated by Ridvan Salih KUZU @DLR
LAST EDITED:  01.06.2021
ABOUT SCRIPT:
It contains some custom metric functions exploited for experimental purposes in this project.
"""
from keras_unet_collection import models
from model_zoo.mobile_unet import MobileUnet
from model_zoo.sim_clr import SimCLR
from tensorflow.keras.initializers import RandomNormal
#from model_zoo.classical_unet import Unet_A as Unet
#from model_zoo.adaptive_network_family.adaptive_unet import AdaptiveUNet
from model_zoo.double_unet import DoubleUnet
from model_zoo.adaptive_network_family.adaptive_attention_butterfly import AdaptiveAttentionButterfly, relu_custom
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import *
from tensorflow.keras.optimizers import Nadam, Adam
import matplotlib.pyplot as plt


def get_sim_clr_model(base_model, input_shape):
    '''
      THIS FUNCTION RETURNS SIM-CLR MODEL.
      :param base_model: backbone UNET model
      :param input_shape: (width,height,channel) shape of the input images
      :return: returns simCLR model
     '''
    return SimCLR(base_model,input_shape)



def get_gan_model(model_type,
                  image_stack_shape,
                  input_shape,
                  target_shape,
                  time_series_shape,
                  is_freeze=False):
    gen_model = SpatioTemporalModel(model_type, image_stack_shape, input_shape, time_series_shape,is_freeze=is_freeze)
    gen_model.build(tuple((None, *image_stack_shape)))
    #gen_model.summary()
    disc_model = DiscriminatorModel(image_stack_shape, target_shape)
    disc_model.build([tuple((None, *image_stack_shape)),tuple((None, *target_shape))])
    #disc_model.summary()
    return GAN(gen_model,disc_model)



def get_generator_model(model_type, image_stack_shape, input_shape, time_series_shape):


    return SpatioTemporalModel(model_type, image_stack_shape, input_shape,time_series_shape, is_freeze=False)

def get_discriminator_model(image_stack_shape, target_shape):


    return DiscriminatorModel(image_stack_shape, target_shape)



class GAN(tf.keras.Model):
    def __init__(self, gen_model,disc_model):
        super(GAN, self).__init__()
        self.gen_model=gen_model
        self.disc_model=disc_model
        self.ema_gen_model = tf.keras.models.clone_model(self.gen_model)
        self.ema=0.99


    def call(self, data, training=False):
        input_image, target_image = data
        gen_output = self.generate(data, training=training)
        disc_real_output = self.disc_model([input_image, target_image], training=training)
        disc_gene_output = self.disc_model([input_image, gen_output], training=training)
        return gen_output

    def generate(self, data, training=False):
        input_image, target_image = data
        if training:
            generated_images = self.gen_model(input_image, training=training)
        else:
            generated_images = self.ema_gen_model(input_image, training=training)
        return generated_images


    def compile(self, g_optimizer,d_optimizer, gen_loss,disc_loss,corr_metric,batch_size, **kwargs):
        super(GAN, self).compile(**kwargs)
        self.d_optimizer = d_optimizer
        self.g_optimizer = g_optimizer
        self.gen_loss = gen_loss
        self.disc_loss=disc_loss
        self.corr_metric=corr_metric
        self.batch_size=batch_size

        self.generator_loss_tracker_train = tf.keras.metrics.Mean(name="loss")
        self.discriminator_loss_tracker_train = tf.keras.metrics.Mean(name="d_loss")
        self.L1_loss_tracker_train = tf.keras.metrics.Mean(name="l1_loss")
        self.correlation_tracker_train = tf.keras.metrics.Mean(name="corr_metric")

        #self.generator_loss_tracker_val = tf.keras.metrics.Mean(name="g_loss_val")
        #self.discriminator_loss_tracker_val = tf.keras.metrics.Mean(name="d_loss_val")
        #self.L1_loss_tracker_val = tf.keras.metrics.Mean(name="l1_loss_val")
        #self.correlation_tracker_val = tf.keras.metrics.Mean(name="corr_metric_val")

    @property
    def train_metrics(self):
        return [
            self.generator_loss_tracker_train,
            self.discriminator_loss_tracker_train,
            self.L1_loss_tracker_train,
            self.correlation_tracker_train,
        ]

    @property
    def test_metrics(self):
        return [
            self.generator_loss_tracker_val,
            self.discriminator_loss_tracker_val,
            self.L1_loss_tracker_val,
            self.correlation_tracker_val,
        ]


    def test_step(self, data): #TODO https://keras.io/guides/customizing_what_happens_in_fit/
        input_image, target_image = data
        gen_output = self.gen_model(input_image, training=False)
        disc_real_output = self.disc_model([input_image, target_image], training=False)
        disc_gene_output = self.disc_model([input_image, gen_output], training=False)

        gen_total_loss, gen_gan_loss, gen_l1_loss = self.gen_loss(disc_gene_output, gen_output, target_image,self.batch_size)
        disc_loss = self.disc_loss(disc_real_output, disc_gene_output, self.batch_size)
        corr_metric = self.corr_metric(gen_output, target_image)

        self.generator_loss_tracker_train.update_state(gen_total_loss)
        self.L1_loss_tracker_train.update_state(gen_l1_loss)
        self.discriminator_loss_tracker_train.update_state(disc_loss)
        self.correlation_tracker_train.update_state(corr_metric)

        return {m.name: m.result() for m in self.train_metrics[:]}


    def train_step(self, data):
        input_image, target_image = data
        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
            gen_output = self.gen_model(input_image,training=True)
            disc_real_output = self.disc_model([input_image, target_image], training=True)
            disc_gene_output = self.disc_model([input_image, gen_output], training=True)

            gen_total_loss, gen_gan_loss, gen_l1_loss = self.gen_loss(disc_gene_output, gen_output, target_image,self.batch_size)
            disc_loss = self.disc_loss(disc_real_output, disc_gene_output,self.batch_size)
            corr_metric=self.corr_metric(gen_output, target_image)

        generator_gradients = gen_tape.gradient(gen_total_loss,self.gen_model.trainable_variables)
        discriminator_gradients = disc_tape.gradient(disc_loss,self.disc_model.trainable_variables)

        self.g_optimizer.apply_gradients(zip(generator_gradients,self.gen_model.trainable_variables))
        self.d_optimizer.apply_gradients(zip(discriminator_gradients,self.disc_model.trainable_variables))

        self.generator_loss_tracker_train.update_state(gen_total_loss)
        self.L1_loss_tracker_train.update_state(gen_l1_loss)
        self.discriminator_loss_tracker_train.update_state(disc_loss)
        self.correlation_tracker_train.update_state(corr_metric)

        # track the exponential moving average of the generator's weights to decrease
        # variance in the generation quality
        for weight, ema_weight in zip(self.gen_model.weights, self.ema_gen_model.weights):
            ema_weight.assign(self.ema * ema_weight + (1 - self.ema) * weight)

        return {m.name: m.result() for m in self.train_metrics[:]}
        #disc_real_output = self.disc_model([input_image, target_image], training=True)
        #disc_gen_output = self.disc_model([input_image, gen_output], training=False)


        #labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)
        # Add random noise to the labels - important trick!
        #labels += 0.05 * tf.random.uniform(tf.shape(labels))
        #temp_in = tf.concat([input_image,input_image],axis=0)
        #temp_tar = tf.concat([target_image, gen_output], axis=0)
        # Train the discriminator
        #with tf.GradientTape(persistent=False) as tape:
        #    disc_output = self.disc_model([temp_in, temp_tar])
        #    d_loss = self.loss_fn(labels, disc_output)
        #grads = tape.gradient(d_loss, self.disc_model.trainable_weights)
        #self.d_optimizer.apply_gradients(zip(grads, self.disc_model.trainable_weights))

        #misleading_labels = tf.zeros((batch_size, 1))
        #with tf.GradientTape() as tape:
        #    gen_output = self.gen_model(input_image)
        #    predictions = self.disc_model([input_image, gen_output])
        #    g_loss = self.loss_fn(misleading_labels, predictions)
        #grads = tape.gradient(g_loss, self.generator.trainable_weights)
        #self.g_optimizer.apply_gradients(zip(grads, self.gen_model.trainable_weights))
        #return {"d_loss": d_loss, "g_loss": g_loss}

    class DiscriminatorModel(tf.keras.Model):

        def __init__(self, image_stack_shape, target_shape):
            # super(SpatioTemporalModel, self).__init__()

            init = RandomNormal(stddev=0.02)
            # source image input
            in_src_image = Input(shape=image_stack_shape)
            # target image input
            in_target_image = Input(shape=target_shape)
            # concatenate images channel-wise
            merged = Concatenate()([in_src_image, in_target_image])
            # C64
            d = Conv2D(64, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(merged)
            d = LeakyReLU(alpha=0.2)(d)
            # C128
            d = Conv2D(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d)
            d = BatchNormalization()(d)
            d = LeakyReLU(alpha=0.2)(d)
            # C256
            d = Conv2D(256, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d)
            d = BatchNormalization()(d)
            d = LeakyReLU(alpha=0.2)(d)
            # C512
            d = Conv2D(512, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d)
            d = BatchNormalization()(d)
            d = LeakyReLU(alpha=0.2)(d)
            # second last output layer
            d = Conv2D(512, (4, 4), padding='same', kernel_initializer=init)(d)
            d = BatchNormalization()(d)
            d = LeakyReLU(alpha=0.2)(d)
            # patch output
            d = Conv2D(1, (4, 4), padding='same', kernel_initializer=init)(d)
            # d = Activation('sigmoid')(d)

            super(DiscriminatorModel, self).__init__(inputs=[in_src_image, in_target_image], outputs=d)

def _get_backbone(model_type, input_shape, is_freeze=False):
        '''
        THIS FUNCTION RETURNS a UNET MODEL VARIANT.
        :param model_type: model architecture index; 0: MobileUNet, 1: UNet, 2: ResUNet, 3:AttentionUNet with ResNet, 4:AttentionUNet with EfficientNet-B0, 5:AttentionUNet with EfficientNet-B7, 6:Attention UNet without backbone
        :param input_shape: (width,height,channel) shape of the input images
        :param is_freeze: it determine if the backbone will be frozen or not in training
        :return: returns a UNET model variant
        '''

        if model_type == 0:
            return MobileUnet(input_shape=input_shape, freeze_backbone=is_freeze)
        elif model_type == 1:
            return models.unet_2d(input_shape, [32, 64, 128, 256, 512], 1, stack_num_down=5, stack_num_up=5,
                                  batch_norm=True, pool=True, unpool=True, output_activation='ReLU', weights=None,
                                  freeze_batch_norm=False)  # Unet(input_shape=input_shape)
        elif model_type == 2:
            return models.vnet_2d(input_shape, filter_num=[16, 32, 64, 128, 256], n_labels=1,
                                  res_num_ini=1, res_num_max=3, activation='ReLU', output_activation='ReLU',
                                  batch_norm=True, pool=True, unpool=True, name='vnet')

        elif model_type == 3:
            model = models.att_unet_2d(input_shape, [32, 64, 128, 256, 512], n_labels=1, stack_num_down=2,
                                       stack_num_up=2,
                                       backbone=None, activation='LeakyReLU',
                                       atten_activation='LeakyReLU', attention='multiply',
                                       output_activation='LeakyReLU', batch_norm=True,
                                       pool=True, unpool=True, freeze_batch_norm=False, freeze_backbone=is_freeze,
                                       name='attunet')

            return model
            # inputs = tf.keras.layers.Input(shape=input_shape)
            # x = inputs
            # x = model(x)
            # x = relu_custom(x)
            # return tf.keras.Model(inputs=inputs, outputs=x)

        elif model_type == 4:
            return models.unet_plus_2d(input_shape, [32, 64, 128, 256, 512], n_labels=1,
                                       stack_num_down=2, stack_num_up=2,
                                       activation='ReLU', output_activation='ReLU',
                                       batch_norm=False, pool=True, unpool=True, deep_supervision=True, name='xnet')

        elif model_type == 5:
            return models.unet_3plus_2d(input_shape, n_labels=1, filter_num_down=[32, 64, 128, 256, 512],
                                        filter_num_skip='auto', filter_num_aggregate='auto',
                                        stack_num_down=2, stack_num_up=1, activation='ReLU', output_activation='ReLU',
                                        batch_norm=True, pool=True, unpool=True, deep_supervision=True,
                                        name='unet3plus')

        elif model_type == 6:
            return models.r2_unet_2d(input_shape, [32, 64, 128, 256, 512], n_labels=1,
                                     stack_num_down=2, stack_num_up=1, recur_num=2,
                                     activation='ReLU', output_activation='ReLU',
                                     batch_norm=True, pool='max', unpool=True, name='r2unet')

        elif model_type == 7:
            return models.resunet_a_2d(input_shape, [32, 64, 128, 256, 512],
                                       dilation_num=[1, 3, 5, 7],
                                       n_labels=1, aspp_num_down=256, aspp_num_up=128,
                                       activation='ReLU', output_activation='ReLU',
                                       batch_norm=True, pool=True, unpool=True, name='resunet')

        elif model_type == 8:
            return models.u2net_2d(input_shape, n_labels=1,
                                   filter_num_down=[32, 64, 128, 256, 512],
                                   activation='ReLU', output_activation='ReLU',
                                   batch_norm=True, pool=True, unpool=True, deep_supervision=True, name='u2net')

        elif model_type == 9:
            return models.transunet_2d(input_shape, filter_num=[32, 64, 128, 256, 512], n_labels=1, stack_num_down=2,
                                       stack_num_up=2,
                                       embed_dim=512, num_mlp=1024, num_heads=12, num_transformer=12,
                                       activation='ReLU', mlp_activation='GELU', output_activation='Sigmoid',
                                       batch_norm=True, pool=True, unpool=True, name='transunet')

        elif model_type == 10:
            model = models.swin_unet_2d(input_shape, filter_num_begin=32, n_labels=1, depth=4, stack_num_down=2,
                                        stack_num_up=2,
                                        patch_size=(2, 2), num_heads=[4, 8, 8, 8], window_size=[4, 2, 2, 2],
                                        num_mlp=512,
                                        output_activation='ReLU', shift_window=True, name='swin_unet')

            return model
            # inputs = tf.keras.layers.Input(shape=input_shape)
            # x = inputs
            # x = model(x)
            # x = relu_custom(x)
            # return tf.keras.Model(inputs=inputs, outputs=x)

        # elif model_type == 11:
        #    return CapsNetR3(input_shape=input_shape)
        # elif model_type == 11:
        #    return AdaptiveUNet(input_shape)
        elif model_type == 11:
            return DoubleUnet(input_shape)
        elif model_type == 12:
            return AdaptiveAttentionButterfly(input_shape, max_pools=5, starting_filters=24)
